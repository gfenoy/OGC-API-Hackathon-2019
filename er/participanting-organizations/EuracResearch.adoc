[[EuracResearch]]
=== Eurac Research

Eurac Research (http://www.eurac.edu) is a private not-for-profit research centre established in 1992 with headquarters in Bolzano. Its 430 staff members, united by shared values of passion for their work and an unwavering commitment to quality, have the opportunity to work in a multicultural environment thanks to a wide diversity of nationalities represented among its team. This diversity, of gender and nationality, ensures a positive environment that enables respect and an understanding of different cultural patterns. Eurac Research is internally organized in 11 Research Institutes, supported by 11 Service Departments, performing research activities in different fields from issues related to minority rights protection, federal, regional and local governmental trends and the efficient management of public administrations to studies on renewable energies, promotion of sustainable development and the protection of natural resources. The contributing body for this hackathon is the Institute for Earth Observation (http://www.eurac.edu/en/research/mountains/remsen/Pages/default.aspx) with its research groups for  Advanced Computing for Earth Observation (http://www.eurac.edu/en/research/mountains/remsen/researchfields/Pages/Technology-for-Environmental-Monitoring.aspx). The purpose of the Institute is the advanced analysis of Earth Observation (EO) data and their integration into products and services tackling most relevant environmental issues in mountain areas.

The Group for Advanced Computing for Earth Observation focuses on research in the field of Big Data science for developing and implementing novel technology and methodology for handling and analysis of big earth observation data as well as management and processing of earth observation data for the Institute for Earth Observation.

Participating from Eurac Research: Alexander Jacob - Research Group Leader - Advanced Computing for Earth Observation (alexander.jacob@eurac.edu)

==== Motivation to Participate

Eurac Research is actively contributing to openEO (https://openeo.org/) an open source innovative aiming to federate EO cloud service providers by developing a standardised interface together with back-end and client implementations. This allows users to approach diverse EO data infrastructures, using source code with the same processing commands. Eurac Research develops a back-end driver (https://github.com/Open-EO/openeo-wcps-driver) towards high level interfaces for data cubes via OGC standard WC(P)S and contributes further with the implementation of a use case for operational snow monitoring using openEO.

Since much of the development of OGC API specifications is moving in a similar direction, Eurac Research wanted to participate in the hackathon event in order to improve their understanding of the purpose and orientation of OGC API specifications, as well as to align the implementations as much as possible, in order to make them compatible. Currently several pieces of the openEO API are very similar to the OGC API, since Eurac Research were from the start of the development also looking at what was happening inside the OGC. The RESTful approach of WFS-3, now known as OGC API - Features, was specifically of great interest to Eurac Research. Another related initiative that Eurac Research is monitoring and following is the development of the Spatial Temporal Asset Catalogue (STAC) of the Radiant Earth Foundation (https://github.com/radiantearth/stac-spec).

==== Implemented Solution

During the hackathon event in London, Eurac Research participated in the further development of the OGC API - Coverages specification on the first day and then developed a number of back-end implementations. Alexander also implemented the latest agreed-on specification on the second day of the hackathon. The implementation was based on the Web Coverage Processing Service (WCPS) and is available at: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/.

This solution is based on the aforementioned openEO WCPS driver and has adopted some new REST endpoints considering the OGC API - Coverages specification.
In particular:

* /collections
** lists all available collections within server. For this hackathon two collections have been hard-coded for demonstration purposes only: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/collections
* /collections/{collectionid}
** lists all available coverages in collections specified within server, including most essential metadata like spatial and temporal extent of all coverages: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/collections/Sentinel-2
* /collections/{collectionid}/coverages
** currently identical to /collections/{collectionid}: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/collections/Sentinel-2/coverages
* /collections/{collectionid}/coverages/{coverageid}
** this endpoint is supposed to deliver the actual coverage in its native format or a specified format and subset via query parameters. In the current implementation however it is just delivering the metadata: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/collections/Sentinel-2/coverages/openEO_S2_32632_20m_L2A
* /coverages
** lists all available coverages, independently of whether they belong to collections or not. This listing includes most essential metadata like spatial and temporal extent of all coverages: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/coverages/
* /coverages/{coverageid}
** this endpoint gives actual access to the data included in a coverage. The following examples demonstrates also how query parameters can be used to limit to a specific subset along all available dimensions of the coverage and how a specific output format can be specified: http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/coverages/openEO_S2_32632_60m_L2A&format=json&subset=E(399960,419960)&subset=N(5090220,5100220)&subset=DATE(%222018-06-04%22). Available query parameters are:
*** format
**** available formats are listed at http://saocompute.eurac.edu/openEO_WCPS_Driver/openeo/output_formats
*** subset
**** works just like the original subset from WCS 2

The existing driver works on top of an installation of Rasdaman community edition, exposing both the already existing WCS 2 and its WCPS 1 extension.

==== Proposed Alternatives

Alexander proposed the direct use of the path `/collections/{collectionid}/{coverageid}` instead of the path `/collections/{collectionid}/coverages`. The reason being that if collections can have different types of collections e.g. a feature collection and a coverage collection, it may be more appropriate that this information is delivered in the metadata of the collection with a type field.

==== Experiences with OGC API Specifications

The overall impression of the Hackathon was, for Alexander, that there still needs to be more integration between the different OGC API specifications. The goal should not be to just "restify" the existing standards, but to create a new well-defined suite of functionality that takes the current state of available data and technology into account. Most importantly the data available today is multidimensional, covering at least 3 or more dimensions that should be considered everywhere in the API. Secondly, in order to make actual use of the enormous amount of data available today, one cannot simply download the data an then process everything on the client-side. Processing should be performed as much as possible, where the data is, in order to avoid unnecessary copies, and unnecessary delay due to long Input/Output times. Finally processing should be as flexible as possible and allow for chaining of arbitrary functions or operations in order to allow a user to achieve whatever he wants with the data. Here, Alexander urges OGC to look into how processing is designed in openEO (https://open-eo.github.io/openeo-api/v/0.4.1/index.html) with its concept of a graph representation of workflows, that can contain any number of processes chained into arbitrarily complex graphs including even user-defined functions, when necessary processes are not natively supported by a given back-end implementation.

==== Other Impressions & Recommendations

The concept of collections of coverages needs to be further specified more precisely. In particular it needs to be discussed and decided if collections should have the same projection and underlying grid, or if they can have arbitrary projections and grids. In the latter case a defined behavior should be decided of how to access a collection as opposed to an individual coverage. Questions like how are we mosaicking and integrating data from coverages on-the-fly when belonging to same collections, need to be answered. Are re-sampling methods, blending and mosaicking decided implicitly by the back-end implementation or can those be selected by query parameters or other means as well? How do we deal with multi-temporal (or arbitrary n-dimensional) mosaicking and resampling?
